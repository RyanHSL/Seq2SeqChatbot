[strings]
# Mode : train, test, serve
mode = serve
train_data=train_data
seq_data = Data/train_data/seq.data
vocab_inp_path=Data/train_data/inp.vocab
vocab_tar_path=Data/train_data/tar.vocab
resource_data = Data/train_data/dialogs.txt
split_train_data=Data/train_data/seq_data_
e = E
m = M
model_data = model_data
log_dir=log_dir
[ints]
BATCH_SIZE = 64
EPOCHS = 5
LATENT_DIM = 400
LATENT_DIM_DECODER = 400
NUM_SAMPLES = 20000
MAX_SEQUENCE_LENGTH = 100
MAX_NUM_WORDS = 20000
EMBEDDING_DIM = 100
vocab_inp_size = 20000
vocab_tar_size = 20000
train_epoch=10
layer_size = 512
number_work=2
num_examples = 30000
[floats]
min_loss=0.2